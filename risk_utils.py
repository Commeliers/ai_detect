import fitz
from PIL import Image, ImageOps
import pytesseract
import io
import re
import pandas as pd
import requests
from bs4 import BeautifulSoup

# âœ… Tesseract ê²½ë¡œ ì„¤ì • (Mac ê¸°ì¤€)
pytesseract.pytesseract.tesseract_cmd = "/opt/homebrew/bin/tesseract"

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬
def preprocess_image(img):
    gray = img.convert("L")
    enhanced = ImageOps.autocontrast(gray)
    binarized = enhanced.point(lambda x: 0 if x < 180 else 255, '1')
    return binarized

# âœ… í•œê¸€ë§Œ ì¶”ì¶œ
def clean_korean_text(text):
    return ''.join(re.findall(r'[ê°€-í£]', text))

# âœ… PDFì—ì„œ ì£¼ì†Œ ë° ê±´ë¬¼ëª… ì¶”ì¶œ
def extract_address_and_building_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        pix = page.get_pixmap(dpi=400)
        img = Image.open(io.BytesIO(pix.tobytes()))
        img = preprocess_image(img)
        page_text = pytesseract.image_to_string(img, lang="kor+eng", config="--psm 6 --oem 1")
        text += page_text + "\n"

    match = re.search(r"\[\s*ì§‘\s*í•©\s*ê±´\s*ë¬¼\s*\]\s*([^\n]+)", text)
    if not match:
        print("âŒ '[ì§‘í•©ê±´ë¬¼]' ì¤„ ì—†ìŒ")
        return None, None

    line = match.group(1).strip()
    words = line.split()

    dong_end_idx = -1
    for i, word in enumerate(words):
        if 'ë™' in word:
            dong_end_idx = i
        if re.match(r"\d{1,4}-?\d*", word):
            dong_end_idx = i - 1
            break

    if dong_end_idx < 3:
        return None, None

    region = words[0]
    citygu = words[1] + words[2]
    dong = ''.join(words[3: dong_end_idx + 1])
    address = f"{region} {citygu} {dong}"

    building_words = words[dong_end_idx + 2:]
    cleaned = [w for w in building_words if not re.search(r"(ì œ|\d+í˜¸|ì¸µ|ë™|\d+)", w)]
    building_name = clean_korean_text(''.join(cleaned))

    return address.strip(), building_name

# âœ… ì£¼ì†Œ â†’ ë²•ì •ë™ì½”ë“œ
def get_lawd_cd(address, csv_path):
    parts = address.split()
    if len(parts) < 3:
        print("âŒ ì£¼ì†Œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None

    ì‹œë„, ì‹œêµ°êµ¬, ìë©´ë™ = parts[0], parts[1], parts[2]
    df = pd.read_csv(csv_path, dtype=str)

    match = df[
        (df["ì‹œë„ëª…"] == ì‹œë„) &
        (df["ì‹œêµ°êµ¬ëª…"] == ì‹œêµ°êµ¬) &
        (df["ìë©´ë™ëª…"] == ìë©´ë™)
    ]

    if not match.empty:
        return match.iloc[0]["ë²•ì •ë™ì½”ë“œ"][:5]
    else:
        print("âŒ ë²•ì •ë™ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

# âœ… PDF ì „ì²´ OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_pdf_with_ocr(pdf_path):
    doc = fitz.open(pdf_path)
    full_text = ""
    for page in doc:
        pix = page.get_pixmap(dpi=400)
        img = Image.open(io.BytesIO(pix.tobytes()))
        img = preprocess_image(img)
        text = pytesseract.image_to_string(img, lang="kor+eng", config="--psm 6 --oem 1")
        full_text += text + "\n"
    return full_text

# âœ… ì‹¤ê±°ë˜ê°€ ì¡°íšŒ
def get_latest_officetel_trade(lawd_cd, building_name, area, service_key):
    url = "http://apis.data.go.kr/1613000/RTMSDataSvcOffiTrade/getRTMSDataSvcOffiTrade"
    result = []

    for month in range(1, 13):
        deal_ymd = f"2024{month:02d}"
        print(f"ğŸ“¦ {deal_ymd} ì¡°íšŒ ì¤‘...")
        params = {
            "serviceKey": service_key,
            "LAWD_CD": lawd_cd,
            "DEAL_YMD": deal_ymd,
            "pageNo": "1",
            "numOfRows": "100"
        }

        response = requests.get(url, params=params)
        soup = BeautifulSoup(response.text, "xml")
        items = soup.find_all("item")

        for item in items:
            try:
                result.append({
                    "ë‹¨ì§€ëª…": item.find("offiNm").text,
                    "ì „ìš©ë©´ì ": float(item.find("excluUseAr").text),
                    "ê³„ì•½ì¼": f"{item.find('dealYear').text}-{item.find('dealMonth').text}-{item.find('dealDay').text}",
                    "ê±°ë˜ê¸ˆì•¡(ë§Œì›)": item.find("dealAmount").text
                })
            except:
                continue

    df = pd.DataFrame(result)
    df_filtered = df[df["ë‹¨ì§€ëª…"].str.contains(building_name, na=False)].copy()
    df_filtered["ë©´ì ì°¨ì´"] = abs(df_filtered["ì „ìš©ë©´ì "] - area)
    df_filtered["ê³„ì•½ì¼"] = pd.to_datetime(df_filtered["ê³„ì•½ì¼"], errors="coerce")
    df_filtered = df_filtered.dropna(subset=["ê³„ì•½ì¼"])
    if df_filtered.empty:
        print("âŒ ì¡°ê±´ì— ë§ëŠ” ê±°ë˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    latest = df_filtered.sort_values(["ë©´ì ì°¨ì´", "ê³„ì•½ì¼"], ascending=[True, False]).head(1).squeeze()

    return latest

# âœ… OCR í…ìŠ¤íŠ¸ â†’ íŠ¹ì§• ì¶”ì¶œ
def parse_ocr_text_to_features(text, jeonse_ratio):
    text = text.replace(" ", "")
    
    def contains(keyword):
        return int(keyword in text)

    def normalize_mortgage(text):
        matches = re.findall(r'ê·¼ì €ë‹¹ê¶Œì„¤ì •ê¸ˆ(\d+,\d+|\d+)', text)
        values = [int(m.replace(',', '')) for m in matches]
        if not values:
            return 0
        max_value = max(values)
        return max_value / 1_0000_0000

    return {
        "ì „ì„¸ê°€ìœ¨": jeonse_ratio,
        "ì‹ íƒ": contains("ì‹ íƒ"),
        "ê·¼ì €ë‹¹ì •ê·œí™”": normalize_mortgage(text),
        "ê°€ì••ë¥˜": contains("ê°€ì••ë¥˜"),
        "ì••ë¥˜": contains("ì••ë¥˜"),
        "ì†Œìœ ê¶Œì´ì „": contains("ì†Œìœ ê¶Œì´ì „"),
        "ì„ì°¨ê¶Œë“±ê¸°ëª…ë ¹": contains("ì„ì°¨ê¶Œë“±ê¸°ëª…ë ¹")
    }

# âœ… ìœ„í—˜ ì ìˆ˜ í•´ì„
def interpret_risk_score(score):
    if score >= 80:
        return "ë§¤ìš° ë†’ìŒ", "âš ï¸ ë³´ì¦ê¸ˆ ë°˜í™˜ì´ ì–´ë ¤ìš¸ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤."
    elif score >= 60:
        return "ë†’ìŒ", "âš ï¸ ë³´ì¦ê¸ˆ ë°˜í™˜ì— ìœ„í—˜ ìš”ì†Œê°€ ì¡´ì¬í•©ë‹ˆë‹¤."
    elif score >= 40:
        return "ë³´í†µ", "âš ï¸ ì¼ë¶€ ìœ„í—˜ ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤."
    elif score >= 20:
        return "ë‚®ìŒ", "âœ… ìœ„í—˜ ìš”ì†ŒëŠ” ì ì€ í¸ì…ë‹ˆë‹¤."
    else:
        return "ë§¤ìš° ë‚®ìŒ", "âœ… ìœ„í—˜ ìš”ì†Œê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤."
